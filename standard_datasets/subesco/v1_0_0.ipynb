{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b84c17",
   "metadata": {},
   "source": [
    "# 0. Imports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c7c6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d03d4",
   "metadata": {},
   "source": [
    "# 1. Download the data\n",
    "---\n",
    "\n",
    "- The data will be downloaded to the `download` directory\n",
    "- The wav files will be moved to the `audios` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff7d0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "source=\"https://zenodo.org/records/4526477/files/SUBESCO.zip?download=1\"\n",
    "\n",
    "# download zip\n",
    "zip_path = join(\"download\",\"zip_files\",\"subesco.zip\")\n",
    "if not os.path.exists(zip_path):\n",
    "  os.makedirs(join(\"download\",\"zip_files\"), exist_ok=True)\n",
    "  urllib.request.urlretrieve(source, zip_path)\n",
    "\n",
    "download_dir = join(\"download\",\"subesco\")\n",
    "audio_dir = join(\"audios\",\"subesco\")\n",
    "\n",
    "# unpack zip\n",
    "if not os.path.exists(download_dir):\n",
    "  os.makedirs(download_dir)\n",
    "  shutil.unpack_archive(zip_path, download_dir)\n",
    "\n",
    "# move audio files to `./audios`\n",
    "if not os.path.exists(audio_dir):\n",
    "  os.makedirs(audio_dir)\n",
    "  src=join(download_dir,\"SUBESCO\")\n",
    "  for file in os.listdir(src):\n",
    "    shutil.copy2(join(src, file) , audio_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed00b9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. Preprocessing\n",
    "---\n",
    "\n",
    "- create tables\n",
    "- set filepaths as index\n",
    "- normalize lables\n",
    "  - rename categorical labels to nouns\n",
    "  - scale numerical labels to range (0, 1)\n",
    "- filter bad annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8492831",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if 'F_02_MONIKA_S_2_SURPRISE_3].wav' in os.listdir(audio_dir):\n",
    "  os.rename(\n",
    "      join(audio_dir,'F_02_MONIKA_S_2_SURPRISE_3].wav'),\n",
    "      join(audio_dir,'F_02_MONIKA_S_2_SURPRISE_3.wav')\n",
    "  )\n",
    "\n",
    "# create DataFrame containing audio files\n",
    "index = pd.Index(os.listdir(audio_dir))\n",
    "df = pd.DataFrame(index=index)\n",
    "\n",
    "\n",
    "# define maps to normalize labels\n",
    "gender_map={\"M\":\"male\",\"F\":\"female\"}\n",
    "\n",
    "emotion_map={\n",
    "    'SURPRISE' : 'surprise',\n",
    "    'NEUTRAL' : 'neutral',\n",
    "    'DISGUST' : 'disgust',\n",
    "    'HAPPY' : 'happiness',\n",
    "    'SAD' : 'sadness',\n",
    "    'FEAR' : 'fear',\n",
    "    'ANGRY' : 'anger',\n",
    "}\n",
    "\n",
    "get_take=lambda x: int(x.replace(\".wav\",\"\"))\n",
    "\n",
    "# set columns\n",
    "df[\"gender\"]=df.index.str.split(\"_\").str[0].map(gender_map)\n",
    "df[\"speaker_number\"]=df.index.str.split(\"_\").str[0:2].str.join(\"_\") # see paper\n",
    "df[\"speaker\"]=df.index.str.split(\"_\").str[2]\n",
    "df[\"sentence\"]=df.index.str.split(\"_\").str[3:5].str.join(\"_\")\n",
    "df[\"emotion\"]=df.index.str.split(\"_\").str[5].map(emotion_map)\n",
    "df[\"take\"]=df.index.str.split(\"_\").str[6].map(get_take)\n",
    "\n",
    "# create tables dir\n",
    "tables_dir = \"tables\"\n",
    "if not os.path.exists(tables_dir):\n",
    "  os.makedirs(tables_dir)\n",
    "\n",
    "# save files table\n",
    "df.to_csv(join(\"tables\",\"subesco_files.csv\"))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c4dd5",
   "metadata": {},
   "source": [
    "## 3. create train/test split\n",
    "---\n",
    "\n",
    "create splits, which are:\n",
    "- **speaker independent**\n",
    "- **gender balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc324efd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dimensions = [\"arousal\", \"valence\", \"dominance\"]\n",
    "# select speakers randomly\n",
    "speakers = df.speaker.unique()\n",
    "np.random.seed(42)\n",
    "test_speakers = np.random.choice(speakers, size=2, replace=False)\n",
    "train_speakers = [sp for sp in speakers if not sp in test_speakers]\n",
    "\n",
    "# shuffle dataframe\n",
    "shuffled_df = shuffle(df, random_state=8)\n",
    "\n",
    "# split data into train/test dataframes\n",
    "test_df = shuffled_df[shuffled_df.speaker.isin(test_speakers)]\n",
    "train_df = shuffled_df[shuffled_df.speaker.isin(train_speakers)]\n",
    "\n",
    "# save tables as csv\n",
    "test_df[\"emotion\"].to_csv(join(\"tables\",\"quechua_emotions_test.csv\"))\n",
    "train_df[\"emotion\"].to_csv(join(\"tables\",\"quechua_emotions_train.csv\"))\n",
    "for dimension in dimensions:\n",
    "  test_df[dimension].to_csv(join(\"tables\",f\"quechua_{dimension}_test.csv\"))\n",
    "  train_df[dimension].to_csv(join(\"tables\",f\"quechua_{dimension}_train.csv\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
